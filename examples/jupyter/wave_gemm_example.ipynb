{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "Before running this notebook, make sure you have the `iree-turbine` package installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install iree-turbine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wave GEMM Kernel Tutorial\n",
    "\n",
    "This tutorial demonstrates how to write a simple GEMM (General Matrix Multiplication) kernel using the Wave language. We'll walk through the implementation step by step. First, we need to add the necessary imports and define the symbols we will be using in the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iree.turbine.kernel._support.indexing import sym\n",
    "from iree.turbine.kernel._support.dtype import f16, f32\n",
    "from iree.turbine.kernel.lang.wave_types import *\n",
    "from iree.turbine.kernel.lang.global_symbols import *\n",
    "from iree.turbine.kernel.wave.utils.run_utils import set_default_run_config\n",
    "import iree.turbine.kernel as tkl\n",
    "import iree.turbine.kernel.wave as tkw\n",
    "from iree.turbine.kernel.wave.compile import WaveCompileOptions, wave_compile\n",
    "import torch\n",
    "\n",
    "# Define symbolic dimensions for our matrices\n",
    "M = sym.M  # Rows of A and C\n",
    "N = sym.N  # Rows of B and columns of C\n",
    "K = sym.K  # Columns of A and B\n",
    "\n",
    "# Define workgroup tile sizes\n",
    "BLOCK_M = sym.BLOCK_M\n",
    "BLOCK_N = sym.BLOCK_N\n",
    "BLOCK_K = sym.BLOCK_K\n",
    "\n",
    "# Define the address space for our memory\n",
    "ADDRESS_SPACE = sym.ADDRESS_SPACE\n",
    "GLOBAL_ADDRESS_SPACE = sym.GLOBAL_ADDRESS_SPACE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Precision GEMM Kernel Implementation\n",
    "\n",
    "Our GEMM kernel will compute C = A @ B.T, where:\n",
    "- A is an M×K matrix in f16\n",
    "- B is a NxK matrix in f16\n",
    "- C is an M×N matrix in f32\n",
    "\n",
    "Below, we will define the constraints which specify how we want to distribute the different dimensions of our problem. Then, we will define the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constraints for the kernel\n",
    "constraints = [\n",
    "    tkw.WorkgroupConstraint(M, BLOCK_M, 0),\n",
    "    tkw.WorkgroupConstraint(N, BLOCK_N, 1),\n",
    "    tkw.TilingConstraint(K, BLOCK_K),\n",
    "    tkw.WaveConstraint(M, BLOCK_M / 2),\n",
    "    tkw.WaveConstraint(N, BLOCK_N / 2),\n",
    "    tkw.HardwareConstraint(\n",
    "        threads_per_wave=64,\n",
    "        waves_per_block=(2, 2, 1),\n",
    "        mma_type=tkw.MMAType.F32_16x16x16_F16\n",
    "    )\n",
    "]\n",
    "\n",
    "@tkw.wave(constraints)\n",
    "def gemm(\n",
    "    a: Memory[M, K, ADDRESS_SPACE, f16],  # Input matrix A\n",
    "    b: Memory[N, K, ADDRESS_SPACE, f16],  # Input matrix B\n",
    "    c: Memory[M, N, GLOBAL_ADDRESS_SPACE, f32],  # Output matrix C\n",
    "):\n",
    "    # Initialize the accumulator register with zeros\n",
    "    c_reg = Register[M, N, f32](0.0)\n",
    "\n",
    "    # Iterate over the K dimension to compute the dot product\n",
    "    @tkw.iterate(K, init_args=[c_reg])\n",
    "    def repeat(acc: Register[M, N, f32]) -> Register[M, N, f32]:\n",
    "        # Load elements from A and B\n",
    "        a_reg = tkw.read(a)\n",
    "        b_reg = tkw.read(b)\n",
    "\n",
    "        # Compute matrix multiplication and accumulate\n",
    "        acc = tkw.mma(a_reg, b_reg, acc)\n",
    "        return acc\n",
    "\n",
    "    # Store the final result to C\n",
    "    tkw.write(repeat, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the GEMM Kernel\n",
    "\n",
    "Let's create a test function to verify our GEMM implementation works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMM test passed!\n"
     ]
    }
   ],
   "source": [
    "def test_gemm():\n",
    "    # Create test matrices\n",
    "    m, n, k = 128, 256, 128  # Small dimensions for testing\n",
    "\n",
    "    # Initialize input matrices with random values\n",
    "    torch.manual_seed(0)\n",
    "    a = torch.randn(m, k, dtype=torch.float16, device=\"cuda\")\n",
    "    b = torch.randn(n, k, dtype=torch.float16, device=\"cuda\")\n",
    "    c = torch.zeros(m, n, dtype=torch.float32, device=\"cuda\")\n",
    "\n",
    "    # Set hyperparameters for compilation\n",
    "    hyperparams = {\n",
    "        ADDRESS_SPACE: SHARED_ADDRESS_SPACE,\n",
    "        BLOCK_M: 64,\n",
    "        BLOCK_N: 64,\n",
    "        BLOCK_K: 32,\n",
    "        M: m,\n",
    "        N: n,\n",
    "        K: k,\n",
    "    }\n",
    "\n",
    "    # Compile the kernel\n",
    "    options = WaveCompileOptions(\n",
    "        subs=hyperparams,\n",
    "    )\n",
    "    options = set_default_run_config(options)\n",
    "    compiled_gemm = wave_compile(options, gemm)\n",
    "\n",
    "    # Run the GEMM kernel\n",
    "    compiled_gemm(a, b, c)\n",
    "\n",
    "    # Verify the result using PyTorch's matmul\n",
    "    expected = torch.matmul(a, b.t())\n",
    "\n",
    "    # Check if results are close (accounting for floating-point precision)\n",
    "    assert torch.allclose(c.to(torch.float16), expected, rtol=1e-2, atol=1e-2), \\\n",
    "        f\"GEMM result doesn't match expected output\\nMax difference: {(c - expected).abs().max()}\"\n",
    "\n",
    "    print(\"GEMM test passed!\")\n",
    "\n",
    "# Run the test\n",
    "test_gemm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of Key Components\n",
    "\n",
    "1. **Memory Types**:\n",
    "   - `Memory[M, K, ADDRESS_SPACE, f16]` defines a matrix in memory with dimensions M×K\n",
    "   - `f16` and `f32` specify the data types (half and single precision)\n",
    "\n",
    "2. **Wave Dialect Features**:\n",
    "   - `@tkw.wave()` decorator with constraints defines the kernel's execution parameters\n",
    "   - `@tkw.iterate` creates a iteration loop over the K dimension\n",
    "   - `Register` represents values in registers during computation\n",
    "\n",
    "3. **Key Operations**:\n",
    "   - `tkw.read` loads values from memory into registers\n",
    "   - `tkw.mma` performs matrix multiplication and accumulation\n",
    "   - `tkw.write` writes results back to memory\n",
    "\n",
    "4. **Constraints**:\n",
    "   - Workgroup constraints define how the computation is tiled\n",
    "   - Wave constraints specify how data is distributed across waves\n",
    "   - Hardware constraints define the execution environment\n",
    "\n",
    "This implementation demonstrates the basic structure of a wave kernel and how to use the wave language's features for efficient matrix multiplication."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
